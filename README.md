# Stockage de donn√©es et transmission de l'information

## Introduction
Ce projet regroupe les travaux pratiques du module "Stockage de donn√©es et transmission de l'information", ax√©s sur la manipulation de HDFS avec Java et Hadoop 3.3.6 dans un environnement Docker. Il contient deux sous-projets :  
- **`HDFS_demo`** : Inclut TP1 (lecture/√©criture HDFS) et TP2 (manipulation avanc√©e de HDFS).  
- **`Hdfs`** : Sp√©cifique √† TP1 avec des ressources suppl√©mentaires.  
**Note importante** : Le code de TP2 se trouve dans `HDFS_demo/src/main/java/ma/mundiapolis/tpHDFS/App2.java`.

## Statut
‚ö†Ô∏è **Statut : TP2 en progression** ‚ö†Ô∏è

## Structure du projet
```
.
‚îú‚îÄ‚îÄ HDFS_demo
‚îÇ   ‚îú‚îÄ‚îÄ HDFSCluster/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ config/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ docker-compose.yaml
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ jars/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ HDFS-1.0-SNAPSHOT.jar
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ test.txt
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ test.sh
‚îÇ   ‚îú‚îÄ‚îÄ README.md
‚îÇ   ‚îú‚îÄ‚îÄ pom.xml
‚îÇ   ‚îú‚îÄ‚îÄ src/main/java/ma/mundiapolis/tpHDFS/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ App1.java (TP1 - Lecture HDFS)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ App2.java (TP2 - Manipulation HDFS)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ AppWriter.java (TP1 - √âcriture HDFS)
‚îÇ   ‚îî‚îÄ‚îÄ target/ (fichiers compil√©s)
‚îî‚îÄ‚îÄ Hdfs
    ‚îú‚îÄ‚îÄ README.md
    ‚îú‚îÄ‚îÄ assets/ (images pour TP1)
    ‚îú‚îÄ‚îÄ config/
    ‚îú‚îÄ‚îÄ docker-compose.yaml
    ‚îú‚îÄ‚îÄ guideme.md
    ‚îú‚îÄ‚îÄ jars/
    ‚îî‚îÄ‚îÄ test.sh
```

## Objectifs de TP2
- Cr√©er `/user/hadoop/appData` dans HDFS s‚Äôil n‚Äôexiste pas.
- Lister les fichiers/r√©pertoires dans `/user/hadoop/appData`.
- Cr√©er `data.txt` dans `/user/hadoop/appData` avec "Bienvenue sur HDFS avec Java".
- Lire et afficher `data.txt`.
- Copier `test.txt` local dans `/user/hadoop/appData/test.txt`.
- T√©l√©charger `/user/hadoop/appData/test.txt` localement.
- Renommer `data.txt` en `data_v1.txt`.
- Supprimer `data_v1.txt`.
- Afficher les m√©tadonn√©es de `test.txt`.
- V√©rifier l‚Äôespace disponible dans HDFS.
- D√©placer `test.txt` vers `/user/hadoop/archive/`.
- √âcrire `products.csv` avec une liste de produits (ID, Nom, Prix).
- Lire et afficher `products.csv` ligne par ligne.

## Pr√©requis
- Docker & Docker Compose üê≥
- Java JDK 8+ ‚òï
- Maven üì¶
- IDE (ex. IntelliJ IDEA) üíª

## Installation et configuration
1. **D√©marrer le cluster Hadoop** :
   - Allez dans `HDFS_demo/HDFSCluster/`.
   - Ex√©cutez : `docker-compose up -d`.
   - V√©rifiez : [http://localhost:9870](http://localhost:9870).
2. **Compiler TP2** :
   - Dans `HDFS_demo/`, ex√©cutez : `mvn clean package`.
3. **Pr√©parer `test.txt`** :
   - `echo "Ceci est un test" > test.txt`.

## Ex√©cution de TP2
Dans `HDFS_demo/`, ex√©cutez :
```bash
java -cp target/HDFS-1.0-SNAPSHOT.jar ma.mundiapolis.tpHDFS.App2
```
Cela lance `App2.java`, qui ex√©cute toutes les t√¢ches de TP2.

## Exemple de sortie
```
R√©pertoire /user/hadoop/appData cr√©√©.
Contenu de /user/hadoop/appData/data.txt :
Bienvenue sur HDFS avec Java.
Fichier test.txt copi√© dans HDFS.
[...]
```

## Notes pour les camarades
‚úÖ TP2 est dans `HDFS_demo/src/main/java/ma/mundiapolis/tpHDFS/App2.java`. Ne confondez pas avec `Hdfs`, qui est uniquement pour TP1 !

## Probl√®mes connus
- ‚ö†Ô∏è Assurez-vous que `test.txt` existe localement, sinon erreur `FileNotFoundException`.

## Conclusion
Ce module explore le stockage distribu√© avec HDFS et Java. TP2, en cours de progression, renforce ces comp√©tences avec des op√©rations avanc√©es. üöÄ
